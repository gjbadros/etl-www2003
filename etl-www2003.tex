%%% $Id$
%%% Copyright (C) 2002 Greg J. Badros <greg.badros@infospace.com>
%%
%
% 30 word statement of contribution:
%
% ETL demonstrates that web templating does not require a full
% programming language. A restricted XML-based language improves
% analyzability, potentially reducing costs and increasing quality by
% eliminating whole classes of errors.
%
% This file should be compiled with V1.0 of "www2003-submission.cls"
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V1.0) produces:
%       1) NO Permission Statement
%       2) WWW'03-specific conference (location) information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%

\documentclass{www2003-submission}
\usepackage{times}
\usepackage{moreverb}
\usepackage{floatflt}
\usepackage{url}

\newcommand{\B}{\discretionary{}{}{}}
\newcommand{\smtt}{\small}
\newcommand{\smtexttt}[1]{{\small\texttt{#1}}}
\newcommand{\ns}[1]{{\small\texttt{#1:*}}}
\newcommand{\figref}[1]{Fig.~\ref{fig-#1}}
\newcommand{\secref}[1]{Section~\ref{sec-#1}}
\newcommand{\ssecref}[1]{Section~\ref{ssec-#1}}
\newcommand{\tableref}[1]{Table~\ref{#1}}
\newcommand{\tm}{{\scriptsize $^{\mbox{tm}}$}}
\newcommand{\gjb}[1]{{\sc gjb:}\textbf{#1}}
%\newcommand{\etl}{\textsf{ETL}}
%\newcommand{\etls}{\textsf{ETLS}}
\newcommand{\etl}{ETL}
\newcommand{\etls}{ETLS}

\newenvironment{smallverbatim}%
{\renewcommand{\baselinestretch}{1}\small\verbatim}%
{\renewcommand{\baselinestretch}{2}\endverbatim}

\newenvironment{smalllisting}%
{\renewcommand{\baselinestretch}{1}\small\listing}%
{\renewcommand{\baselinestretch}{2}\endlisting}

\begin{document}
%
\title{The Extensible Templating Language: \\
       An XML-based Restricted Markup-Generating Language}

\numberofauthors{1}

\author{
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
%% e-mail address with \email.
\alignauthor Greg J. Badros\\
       \affaddr{InfoSpace, Inc., 601 108th Ave. NE, Suite 1200, Bellevue, WA 98004, USA}\\
       \email{greg.badros@infospace.com}
}
\date{14 November 2002}
\maketitle
\begin{abstract}
Popular web templating languages embed general-purpose
programming languages.  The Extensible Templating Language was born
out of questioning the fundamental assumption that the front-end
markup-generating engine of a multi-tier web application requires all
the power and expressiveness implied by that design.  \etl{} restricts
the set of language features to a useful subset that provide the
necessary functionality without compromising the simplicity and
understandability of templates.  By forcibly limiting what can be
done by templates, we ensure a better separation of presentation
details from business logic. Furthermore, \etl{} improves the
analyzability of source templates by using an XML-based
representation where markup is intermingled with XML elements
corresponding to programming constructs. This approach reduces the
possibility of generating improper markup and facilitates tool-building
including semantically-aware editors and debuggers. \etl{} runs inside of
the Extensible Templating Language Server which is currently employed
by InfoSpace to serve millions of requests per day using over
sixty thousand \etl{} templates.

\end{abstract}

% A category with only the three required fields
%% See http://www.acm.org/class/1998/overview.html
\category{D.2}{Software}{Software Engineering}
\category{D.3}{Software}{Programming Languages}
\category{C.2}{Computer Systems Organization}{Networks}

% GREGB:FIXME:: any terms?
%\terms{}

\keywords{Restricted domain-specific programming language, static analysis,
web server, templates, XML, XSLT, markup, WML, HTML\@.}

\section{Introduction}
\label{sec-intro}

The loosely-coupled client/\B{}server model implied by the current
breed of applications deployed via the World Wide Web presents
substantial new complexities for application developers. A variety of
new programming languages and paradigms attempt to address these novel
problems.  One important characteristic of this new world of software
development is the need to generate HTML, WML, and other markup
languages to describe client-side presentation and behaviour.

The original server-side dynamic markup-generation capabilities of the
Web were defined by the Common Gateway Interface~\cite{CGI11}. For each
request of a CGI, the web server maps HTTP request details into environment
variables, command-line arguments, and the standard file descriptors.
In particular, the standard output written by that process was sent by
the Web server as the response to the client browser (instead of
simply responding with an unchanging file from disk).  Over time,
various techniques arose to reduce the cost of each request: extension
mechanisms such as the Apache module system~\cite{Apache} and
scripting languages hosted by the Web server have increased
performance by eliminating process creation overhead.

Today, server-side markup generation is dominated by expressive and
flexible general-purpose programming languages such as
Java~\cite{Arnold98}, Perl~\cite{Camel3rd}, and PHP~\cite{pro_php}.
Ironically, the languages are then mostly used in fairly restricted
ways, often being tied to a templating syntax (e.g., JSP~\cite{JSP12}
for Java or HTML::Template~\cite{HTML-Template} for Perl).  For
example, consider the PHP template in \figref{php-books}.  The only
constructs required by the template are a) some means of populating a
data model from the back-end business logic (line 1); b) data-driven
iteration (line 4); and c) simple expression evaluation to access
parts of the data model (lines 6 and 7). The extra power provided by
typical templating languages not only goes unused, but it also
complicates certain important analyses of the code.  For example, the
obviously critical property that a template's execution terminates is
undecidable for these general purpose languages.

% GREGB:FIXME:: check the above line numbers 

\begin{figure}[tb]
\begin{smalllisting}{1}
<? $books = GetBooks(...); ?>
<html>
 <table>
  <? for ($i=0; $i < count($books); ++$i) { ?>
   <tr>
    <td><? print($books[$i][author]); ?> </td>
    <td><? print($books[$i][title]); ?> </td>
   </tr>
  <? } ?>
 </table>
</htm>
\end{smalllisting}
%$
\caption{Cleanly-written PHP templates require only the simplest
programming language constructs.  Unfortunately, over the evolution of
the presentation layer, PHP developers sometimes engage in far broader
interactions because the power of the language allows them to do so.
\label{fig-php-books}}
\end{figure}

For most web application development frameworks, the restrictions
desired of the front-end templating layer are imposed only by process
and convention.  Template authors are asked to limit themselves to a
subset of the available features of a language as a means of
facilitating scalable, secure, well-behaved systems.  Importantly,
however, there is nothing inherent that prevents presentation code
from, for example, making individual database connections (which would
impact performance) or maintaining undesirable server-side state
(which would impose additional requirements on the load-balancing
mechanism and reduce scalability).  Languages such as PHP actually
encourage this undesirable mixing of front-end presentation with
back-end business logic~\cite{Crane2002}.  That fact further blurs the
common organizational line between front-end presentation developers
and back-end application engineers.

Another substantial problem with existing templating technologies is
that they often involve the lexical mixing of two separate programming
paradigms.  JSP, for example, is implemented in terms of a
pre-processing rewrite of the template into a Java servlet~\cite{JavaServlet23}.
Pre-processing approaches are convenient for programmer expressiveness
but have a huge hidden cost in complicating software engineering
analyses and tools that could otherwise help understand, maintain, and
evolve the complex systems~\cite{Badros00-spe,ErnstBadrosNotkin02}\cite[p.~424]{Stroustrup94}.
The precise analysis of an arbitrary JSP template necessarily requires
full knowledge of both the rewrite rules and the semantics of Java.

\subsection{Restricting the language}

Almost all popular markup templating languages integrate with a
general-purpose programming language.  This approach offers some
advantages.  For example, undoubtedly the language is sufficiently
powerful and expressive for the needs of markup generation.
Additionally, numerous language-level tools such as compilers and
debuggers, are already available for the templating language to
leverage.  For platform providers that have a large
investment already made in a general-purpose language, it is natural
to extend that investment to a templating language.\footnote{XSLT can
be used in a templating style~\cite[2.3]{XSLT}, but popular use of
XSLT also leverages scripting extensions to deal with the far too
severe restrictions of the language.}

Despite the broad assumption that a markup language requires the use
of a general-purpose programming language, an obvious alternative
exists: use a domain-specific language specifically tailored to the
needs of generating markup.  Such an approach can mitigate several of
the problems mentioned previously.  In particular, using a restricted
programming language at the front-end to generate markup can enforce
better separation of front-end presentation from back-end application
logic and may simplify the templates such that they are easier to
write, read, and evolve.

\begin{figure}[tb]
\begin{centering}
\includegraphics[width=.7\linewidth]{web-service-ip-shift.eps}
\vspace*{-.1in}\caption{Web services enable the front-end templating tier to
communicate with back-end applications via standard Internet Protocols
such as XML and SOAP; they no longer need to be aware of distributed
object protocols or data models.\label{fig-ws-ip-shift}}
\end{centering}
\end{figure}

If we limit the functionality of a markup templating language, one
capability that remains important is accessing back-end applications.
The architecture of the classic three-tier application appears at the
top of \figref{ws-ip-shift}.  Historically, the communication between
the front-end and back-end servers uses an object-based data model
and involves remote procedure call mechanisms such as DCOM or Corba.
As the web service architecture depicted in the bottom of
\figref{ws-ip-shift} increases in popularity, the need for the front
end templating language to reason about language-level objects is
reduced.  Instead, the XML data model implied by web services can be
the primary communication format and the front end need only use
Internet standards such as HTTP and XML in interacting with other
applications.  This observation suggests that markup languages need
only concern themselves with a single data model and can thus be made
simpler to learn and use.

%% GIVE EXAMPLES OF VALUABLE ANALYSES!!!
\subsection{Analysis of markup templates}

Given the wide variety of browsers, crawlers, and other user agents,
it is important that the markup created by the presentation layer
conforms to appropriate Internet standards.  For example, WML markup
needs to first be well-formed XML and second be valid with respect to
the appropriate schema or DTD~\cite{WML12}\@.  Although HTML browsers
are more forgiving of variations in syntax, best-practices still
dictate that the markup returned comply with the HTML
specification~\cite{HTML4}.  Popular templating languages including
PHP, JSP, ASP, and many others process arbitrary text and are ignorant
of the rules of the markup being generated: the mistaken close tag on
line 11 of \figref{php-books} goes unnoticed by PHP, yet will result
in a user-perceived complete failure under an XHTML browser.

Tools such as HTMLTidy~\cite{HTMLTidy} are available to check the
responses from servers for conformance, but often testing involves
simply using various browsers to exercise the application while
looking for bugs.  Both of these approaches require exhaustively
visiting every page of interest.  For quality assurance to scale,
we require a way to statically analyze the source templates
themselves to gain confidence that they will, in fact, generate proper
markup.  If static analysis of templates can rule out the possibility
of certain kinds of errors, testing time and costs can be dramatically
reduced.

Another important requirement for software development systems is to
support ad-hoc queries of the source code. For small and simple
dynamic web applications, the automated analysis of templates is often
unnecessary: a web developer or two understands all of the code.  Over
time, however, these simple applications grow in size and complexity
such that tools analyzing the templates become an essential part of
maintaining and evolving the system. For example, a site may wish to
add an extra input field to all of its registration forms.  If a
generic form is not already factored out into a common location, the
first step in approaching the task is finding all the forms. 
Or suppose a new handheld device has a limitation in its
handling of cookies: we need a means of narrowing the scope for careful
review to only places where that cookie is manipulated.

Typically, web developers approach to the above scenarios with an arsenal
of imprecise lexical tools.  While these tools may satisfy some simple
queries, when the desired query has additional structure, lexical
approaches fall short.  Suppose we wish to find dead code to simplify
our application. No regular expression will let us identify all
unreachable templates to satisfy that query.  To analyze more deeply,
we need to uncover the semantic structure of the templating language.
Typically, that requires a language-specific parser and much greater
effort in building a valuable tool or an extensible integrated
development environment~\cite{Soroker97,Eclipse}.

\subsection{XML supports analyses and tools}

An increasingly popular way to perform structured queries of
programming language source code is to use standard XML tools such as
XSLT~\cite{XSLT} and XQuery~\cite{XQuery} to operate over a
complementary XML-based representation~\cite{Badros-www9,Schonger2002,Gondow2002,Power2002}.
With a carefully-chosen XML representation, valuable semantics of the
code are immediately available to XPath expressions, thus enabling
a broad class of source code tools.  However, for a general-purpose
programming language, XML is unwieldy for use as the primary
representation.  Instead, the conventional grammar-based language is
edited by humans and is only converted into XML for the tools to
use.

This research applies the benefits of an XML representation of source
code to the domain of restricted markup templating languages.  Because
web developers are already writing markup directly, it is natural for
them to express the limited logic of their dynamic templates directly
in markup as well.  Importantly, this lets us use a single
representation for both developers and tools. For example, we can use
schema-aware XML editors to easily provide syntax coloring and
completion capabilities.

In this paper, I introduce the Extensible Templating Language.  From
one perspective, \etl{} is an XML-based templating language that
embeds programming constructs directly in the XML
representation, intermingled with literal target-language markup.
Alternatively, we can view \etl{} as an imperative domain-specific
programming language that uses XML as its surface syntax and
simplifies the writing of programs that generate markup languages.

\etl{} leverages well-formedness and local-validity checks of the
source template to support those same properties in the generated
response markup.  By limiting the programming-language constructs to
include only the features that are appropriate at the front-end of a
scalable web application architecture, we ease numerous analyses and
encourage proper separation of the presentation details from the
backend application. Finally, because of its use of XML as a
representation, \etl{} simplifies ad-hoc software engineering analyses to
better support evolution and maintenance of large dynamic web
applications.  We have built an \etl{} runtime inside of a
production-quality web server, the Extensible Templating Language
Server.  InfoSpace runs \etls{} to serve 
millions of requests per day using over sixty thousand \etl{} templates.

\subsection{Outline of paper}

The rest of this paper is organized as follows. \secref{etl} explains
the Extensible Templating Language and its benefits.
\secref{implementation} details our implementation and describes our
experiences in using \etl{} in production systems over the last year.
\secref{related-work} describes and contrasts related work
and \secref{conclusion} concludes.


%%% 
%% GREGB:VISUAL:: avoid too obvious of an overfull hbox below
\section{\hspace*{-.1in}Extensible Templating Language}
\label{sec-etl}

The Extensible Templating Language is an imperative markup templating
language that allows web developers to intermingle literal XML markup
with XML-based programming language constructs.  Our primary design
goals for \etl{} were to:\footnote{A fifth design goal was to
enable automatic translation of our legacy language into
\etl{}\@. This paper focuses only on the essential language, and
\secref{implementation} mentions our migration to \etl{} a bit more.}

\begin{enumerate}
\item Allow easy analyses of source templates to permit development of
supporting tools; 
\item support only the essential programming language constructs
required by a templating layer; 
\item focus on an imperative programming model; and
\item utilize an XML data model pervasively to integrate seamlessly
with Internet and Web standards.
\end{enumerate}

\begin{figure}[tb]
\begin{centering}
\hspace*{-0.05\linewidth}\includegraphics[width=1.1\linewidth]{homesite-screenshot.eps}
\caption{This integrated development environment based
on Homesite was easy to build using custom tag information generated
automatically from the XSD schema for \etl{}\@.  The environment supports
automatic completion of names of elements and their valid attributes.
Help information extracted from the server codebase is also readily
available in the IDE\@.
\label{fig-homesite-screenshot}}
\end{centering}
\end{figure}

An \etl{} template must be well-formed XML that is valid with respect
to the language's XML Schema Definitions~\cite{XMLSchema1,XMLSchema2}.
By enforcing those requirements, we catch a large class of syntactic
and semantic programming errors very early in the development process
without need for the \etl{} compiler at all.  Those schemas are also
used by our development environment (see \figref{homesite-screenshot})
to support syntax coloring and completion of element and attribute
names.  Additionally, because of how easy it is to analyze XML trees,
it is straightforward to build numerous ad-hoc software engineering
tools that are language-aware.  For example, it was trivial to build a
call-graph extractor (see \figref{call-graph}).

%% This was generated using:
%% ~/tigerprawns/etl-interpreter/tools/templates-for-url.pl -r edges-ftr_fast.htm -A "http://stagingetl2/info/ftr_fast.htm"
%%  dot -Tpostscript edges-ftr_fast.htm > ftr_fast-call-graph.eps
\begin{figure*}[bt]
\begin{centering}
\hspace*{-.03\linewidth}\includegraphics[width=1.06\linewidth]{ftr_fast-call-graph.eps}
\caption{This call-graph of templates possibly used in generating an HTML
page footer was extracted using server-side XPath expressions and a
simple Perl script. \label{fig-call-graph}}
\end{centering}
\end{figure*}

\etl{} intentionally restricts the set of programming constructs to
limit the amount of logic performed in the front-end of a multi-tier
web-delivered application.  As a result, we achieve better separation
of presentation and application, thus permitting their independent
evolution. \etl{} is already used by dozens of production
applications, demonstrating that the set of available constructs is
sufficient for real-world use.

\begin{figure}[tb]
\begin{smalllisting}{1}
<?xml version="1.0"?>
<bl:template xmlns:bl="http://www....">
 <bl:set var="#xml/books">...</bl:set>
 <html>
  <table>
   <bl:for-each var="#xml/books/book">
    <tr> 
     <td><bl:get var="@author"/></td>
     <td><bl:get var="@title"/></td>
    </tr>
   </bl:for-each>
  </table>
 </html>
</bl:template>
\end{smalllisting}
\caption{The \etl{} template corresponding to \figref{php-books}'s PHP
code is required to be well-formed XML\@.  Thus, the developer
avoids the mistake from line 11 of the PHP example.
\label{fig-etl-books}}
\end{figure}

An example \etl{} template appears in \figref{etl-books} and is analogous
to the PHP example from \figref{php-books}.  The source code is simply
an XML document with root element \smtexttt{bl:template}\footnote{The
``bl'' stands for ``base language.'' For brevity, we use namespace
prefixes consistently to refer to elements in distinguished namespace URIs.}
The template contains other elements
in the \ns{bl} namespace which we refer to as \etl{} \emph{primitives} (see
\ssecref{primitives}).  Additionally, the template can contain markup
from arbitrary other namespaces (or unqualified elements) which we
call \emph{literal result markup} (see \ssecref{literal-markup}).

\etl{} templates are processed within the context of an HTTP request.
The path specified in the URL of the request selects a template where
processing starts.  The primary goal of
executing a template is to generate an HTTP response including the
markup document along with the various HTTP headers such as the
content-type, cookie settings, and other meta-data.  Generally, an \etl{}
template is similar to a method in an object-oriented programming
language: it can invoke other templates as subroutines and can also
perform subsidiary HTTP requests to other servers (see
\ssecref{control}).

\subsection{Primitives, attributes, and slots}
\label{ssec-primitives}

An \etl{} primitive is an element in the \ns{bl} namespace that has a
specific well-defined behaviour inside of an \etl{} template.  Primitives
either output text to the current destination stream (initially the
response document) or perform some side-effect (or both).  For example
the \smtexttt{bl:set} primitive assigns a variable a value without
outputting any text, while the
\smtexttt{bl:http} primitive outputs either \smtexttt{http} or
\smtexttt{https} based on whether the current request arrived over an
ordinary or secure connection.

The behaviour of a primitive is controlled by its attributes.
Some primitives, such as \smtexttt{http} mentioned above, are always
empty---they never are allowed to contain child elements. Other
primitives are allowed to be non-empty, using the markup generated by
their contained elements as an extra implicit argument.  For example,
in:

\begin{smallverbatim}
<bl:if var="showcopyright"> (C) 2002 </bl:if>
\end{smallverbatim}

\noindent the contents of the \smtexttt{bl:if} are output if and
only if the variable's value is non-empty.

Many primitives derive their arguments not from individual attributes
but from pairs of attributes that are together called a \emph{slot}.  For
example, the \smtexttt{bl:cr} directive outputs linefeeds, and the
number of linefeeds it generates is determined by a slot called
\smtexttt{count}.  That slot is specified using a pair of attributes:
\smtexttt{count} and \smtexttt{count-var}.  The attributes are
mutually-exclusive: it is a statically-checked error to specify both on
the same \smtexttt{bl:cr} element.  The \smtexttt{count} attribute has
type \smtexttt{xsd:integer} and is used to provide a literal integer
argument to the primitive.  In contrast, the \smtexttt{count-var}
attribute has type \smtexttt{bl:identifierType} (a restriction of
\smtexttt{xsd:string}) and names a variable to evaluate at runtime.
In both cases, the resulting value is used as the number of linefeeds
to generate, but for \smtexttt{@count} that number is set statically
while for \smtexttt{@count-var} it is determined dynamically (at
run-time).

Using a pair of attributes to represent a logical field is a novel
mechanism to improve type-safety and ease analysis.  The common
alternative is using a small domain-specific language inside the value
of an attribute.  For example, we could have used \smtexttt{count="2"}
or \smtexttt{count="\$num"} to represent the literal number 2 or the
desire to use the current value of the variable ``num'', respectively.
(XSLT's \smtexttt{value-of} element uses this basic approach.)
Unfortunately, when using a single attribute, the type for the
attribute's value must be broadened and is hence less precise.  That
lack of precision can allow more developer errors to go uncaught.

Primitives can, of course, have numerous arguments, some of which are
controlled by slots and others by individual attributes.  When an
argument is allowed to be set only via an attribute instead of a slot,
that parameter of the directive cannot be influenced at
runtime. Often this restriction is imposed to permit optimizations or
to improve our ability to support static analyses.  For example,
\smtexttt{bl:get} writes out the value of a variable and has a
\smtexttt{@transform} attribute that supports various encodings or
decodings of the value (e.g., \smtexttt{url-encode} or
\smtexttt{xml-decode}---see \ssecref{transformers}).  We disallow the
use of \smtexttt{@transform-var} because we want to always know from
static inspection what transformations may occur, thus facilitating
some analyses and optimizations.

\subsection{Variables and values}
\label{ssec-variables}

As with all imperative programming languages, \etl{} has the notion of
variables that store values. Variables can be declared inside a single
\smtexttt{bl:header} element (which is required to be the first element
in a template) and are assigned values using the
\smtexttt{bl:set} primitive.  The target variable is named via the
\smtexttt{@var} attribute and the value is given by
\smtexttt{@value}, \smtexttt{@value-var}, or by executing the
children of the \smtexttt{bl:set} element.  For example:

\begin{smallverbatim}
<bl:set var="baseuri"><bl:http/>://<bl:get
 var="hostname"/>/</bl:set>
\end{smallverbatim}

\noindent might set the variable named ``baseuri'' to the value
``http://www.\B{}infospace.\B{}com/''.  While executing its contained
elements, \smtexttt{bl:set} redirects the default output stream to be
used to construct a value to assign to the variable; the output stream
is restored after the child elements are processed (e.g., allowing
nesting of \smtexttt{bl:set} primitives).\footnote{Several other
primitives follow this same pattern.  For example
\smtexttt{bl:set-mime-type} evaluates its contained elements to
generate a value to be used for the MIME content-type of the
response.}  

After assignment, values are retrieved by referencing them by name in
a slot or by copying them directly to the output stream using
\smtexttt{bl:get}.  Undeclared variables have dynamic scope and
live until the end of processing the current request, while declared
variables have static scope and may only be referenced in the same
template.

\etl{} has the notion of special reserved variables that may have
side-effects and are used internally for conveying request parameters or
other system-level details.  These reserved variables always start with
the octothorpe (``\smtexttt{\#}'') character and may be read-only (e.g.,
\smtexttt{\#browsertype}) or may alter the behaviour of primitives based
on the value they are assigned.  Unlike ordinary variables, there is
no guarantee that the value retrieved from a reserved variable equals
what was last stored.

Various other data is accessible to \etl{} templates via 
\emph{buckets}. Buckets can be thought of as top-level elements in a virtual
(lazily-evaluated) XML data model that is implicitly available to \etl{}
templates.  They replace field references and accessor methods of
distinguished objects in languages such as Java.  For example, where a
JSP developer might write:

\begin{smallverbatim}
<%= request.getHeader("User-Agent") %>
\end{smallverbatim}

\noindent the \etl{} developer accesses the \smtexttt{\#http}
bucket instead:

\begin{smallverbatim}
<bl:get var="#http/User-Agent"/>
\end{smallverbatim}

\noindent Numerous buckets exist in the XML data model providing ways
to access URL parameters, HTTP headers, user settings,
configuration data for applications and brands, and cookies.

One additional bucket, \smtexttt{\#xml}, is unique in that the values
its variables bind to are XML trees instead of just strings.  When the
variable is evaluated in a context that requires a string, the subtree
is serialized in its XML syntax.  Additionally, a trailing XPath
expression is allowed after the variable name when referencing the
\smtexttt{\#xml} bucket.  This feature allows easy querying of XML
values and integrates XPath cleanly into \etl{}\@.


\subsection{Transformers \& formatters}
\label{ssec-transformers}

HTTP and XML standards have various different encoding formats to
support arbitrary data over channels that allow limited
representations.  For example, when passing a GET parameter to an HTTP
request, the value is inserted into the URL using an URL-encoding
format that involves (among other things) converting each
\smtexttt{SPACE} character to a \smtexttt{+} character.  To support
such encoding formats in a general way, \etl{} defines a set of
``transformers.''

A \emph{transformer} is a streaming converter from one byte sequence
to another.  For example, the \smtexttt{url-encode} transformer
converts ``hello world'' into ``hello+world''.  Many transformers have
an inverse that is also supported: the \smtexttt{url-decode}
transformer converts ``hello+world'' into ``hello world''.
Transformers can be used by \etl{} code whenever a variable is being set
(via \smtexttt{bl:set}) or accessed (via \smtexttt{bl:get}) using the
\smtexttt{transform} attribute which specifies an ordered whitespace-separated
list of transformers to apply.  For example:

\begin{smallverbatim}
<bl:get var="a" transform="trim urlencode"/>
\end{smallverbatim}

\noindent results in writing out the value of the variable \smtexttt{a}
after first eliminating leading and trailing whitespace and then
URL-encoding the resulting trimmed string.  The order of
transformations does matter.  Using

\begin{smallverbatim}
<bl:get var="a" transform="urlencode trim"/>
\end{smallverbatim}

\noindent results in a different output string.  If \smtexttt{a} contains
``\smtexttt{ Hello World }'', the former example produces ``\smtexttt{Hello+World}'' while
the latter variant generates ``\smtexttt{+Hello+World+}'' because the
trimming occurs on the URL-encoded string which already has spaces
replaced by ``\smtexttt{+}'' characters.

\emph{Formatters} are similar to transformers, but their input is a streaming
virtual XML document (similar to SAX, the Simple API for
XML~\cite{SAX}) and their output is a text stream.  Numerous
primitives that generate XML as their output have a
\smtexttt{formatter} slot that names the formatter to use. Several
built-in formatters exist or XSLT stylesheets can be used.  When using
XSLT as a formatter, the events first construct a DOM that is then
transformed via the named stylesheet, letting the stylesheet generate
the formatter's response string.

\subsection{Control flow}
\label{ssec-control}

There are four primary means of control flow in \etl{}: template
selection, conditionals and loops, exceptions, and remote invocations.  

\subsubsection{Template selection}
\label{ssec-selection}

Requests made of the \etl{} server always have an associated abstract
\emph{site} that can be explicitly specified as part of the URL,
or can be implicit based on the \smtexttt{Hostname} header of the HTTP
request (e.g., when multiple hostnames refer to the same server).
That site name is used to select which template is invoked for the
initial processing of a request and whenever the
\smtexttt{bl:call} primitive is used to execute another template as a
subroutine. Template selection is analogous to method dispatch in
object-oriented programming languages.  Importantly, \etl{} only permits
bounded recursion, thus ensuring termination.

For example, an \smtexttt{index.htm} page may \smtexttt{bl:call} a
\smtexttt{header.htm} template to output a banner for the top of a
page, then do some work to generate the meat of the page, and finally
invoke \smtexttt{footer.htm} to generate another banner for the
bottom.  The default \smtexttt{header.htm} at the top-level of the
hierarchy may provide some basic functionality, while an overriding 
\smtexttt{header.htm} implementation could specialize the banner.

\subsubsection{Conditionals and loops}

\etl{} supports both \smtexttt{bl:choose}/\B{}\smtexttt{bl:when}/\B{}\smtexttt{bl:otherwise}
and \smtexttt{bl:if} constructs. They behave much as they do in XSLT\@.  The
primary difference is that \etl{} does not permit the generality of a
domain specific expression language, and instead uses two slots
to represent the guard conditions.  For example:

\begin{smallverbatim}
<bl:if var="pagenum" less-than-var="max-page">
   <a href="...">Next</a>
</bl:if>
\end{smallverbatim}

\noindent Although this is slightly more verbose than a domain-specific
language in a \smtexttt{test} attribute, it does make it easier to use
XPath to find occurrences of specific operations being used in
conditional guards.   Additionally, it allows us to factor out the
left-hand-side value of a comparison guard into the
\smtexttt{bl:choose} parent element to approximate the convenience of
a \smtexttt{switch} statement:

\begin{smallverbatim}
<bl:choose var="pagenum">
  <bl:when less-than="1">..</bl:when>
  <bl:when equals="1">..</bl:when>
  <bl:when greater-than-var="max-page">..</bl:when>
  <bl:otherwise>..</bl:otherwise>
</bl:choose>
\end{smallverbatim}

\noindent where each of the \smtexttt{bl:when} clauses compare the
same variable (without redundant specification of its name).

For looping, only data-driven loops are supported.  Because only
finite data structures exist, this ensures that loops terminate.  A
\smtexttt{bl:for-each} primitive iterates over nodes in a node-set of
an XML variable or splits strings at a specific delimiter and operates
on the substrings.

\subsubsection{Exceptions}

Some primitives throw run-time exceptions.  For example, assigning a
string that contains ill-formed XML to an XML-typed variable results
in a parse exception.  To recover from those exceptions,
\smtexttt{bl:try} blocks that include \smtexttt{bl:catch} and
\smtexttt{bl:finally} children blocks are supported.  Additionally,
templates (especially subroutines) can use \smtexttt{bl:throw} to
generate their own exceptions to be handled by higher stack frames.

\subsubsection{Remote invocation}

Two mechanisms are provided to allow templates to interact with
back-end applications and other hosts.  Simple HTTP requests, both
GETs and POSTs, are supported using a \smtexttt{bl:http-include}
primitive that specifies the URL along with POST data, as required.
Alternatively, a \smtexttt{bl:ws-call} primitive invokes a web service
given its end-point and the arguments to the web service.\footnote{Web
service invocation is a part of an upcoming version of \etls{}\@.} In
both cases, the output of the primitive is the document returned by
the server.

\subsection{Literal markup}
\label{ssec-literal-markup}

While typical templating languages are text-based, \etl{} is
based instead on the higher level abstraction of markup.
It is this distinction that enables \etl{} to favor
generating well-formed output documents.  For example, an ASP template
might read:

\begin{smallverbatim}
<a href="<%= target %>"><%= link_name %></a>
\end{smallverbatim}

\noindent which has semantics that are strictly textual---it concerns
itself with outputting arbitrary character sequences.  Unfortunately,
this snippet:

\begin{smallverbatim}
<a hre=<%= target %>><%= link_name %></b>
\end{smallverbatim}

\noindent is essentially the same as the preceding code, despite the
fact that this second example contains several errors.

As a markup-based templating language, \etl{} favors writing templates
that will generate well-formed and valid markup.  For example, to
output a literal XML fragment such as ``\smtexttt{<b>Good</b>}'', that
fragment can be written directly in the \etl{} template.  However, to
generate the ill-formed XML fragment ``\smtexttt{<a>Bad</b>}'', you
must fall back on outputting individual characters and write:

\begin{smallverbatim}
&lt;a&gt;Bad&lt;/b&gt;
\end{smallverbatim}

\noindent Note that \etl{} does not forbid outputting ill-formed
markup, it only encourages proper markup by making that common case
far more natural to write.

Of course, the markup we need to output often includes dynamically
computed attributes and content (as with our initial ASP example).  To
output an attribute with its value derived from a variable, you can
write:

\begin{smallverbatim}
<a href="?target">...</a>
\end{smallverbatim}

\noindent where the \smtexttt{?target} syntax means to use the value
of variable ``target'' rather than the literal characters
\smtexttt{?target}\footnote{A leading backslash is ignored and suppresses the special
meaning of the question mark in case you really do want the attribute
to be set to those seven characters.}
Alternatively, one can write:

\begin{smallverbatim}
<a><at:href><bl:get var="target"></at:href>...</a>
\end{smallverbatim}

\noindent Here, the \smtexttt{href} attribute of the \smtexttt{a}
element is given the value computed by evaluating the elements
contained by \smtexttt{at:href}.  The special namespace \smtexttt{at}
is used to make this format more concise than the long-winded
\smtexttt{xsl:attribute} variant that XSLT uses.  The local name of the
\smtexttt{at:*} element is used as the name of the attribute, and the
contents can be arbitrary \etl{} code (e.g., including conditionals and
subroutines). No matter which form is used to specify dynamic
attribute values, the language ensures that proper quotations and
encoding are used.  Furthermore, by using the DTD or XSD of the
output document's desired markup language, we can confirm that
attribute names (and sometimes their values) are correct.

Another common need is to conditionally include a tag.  For example,
consider this ill-formed template fragment:

\begin{smallverbatim}
<bl:if var="#pro/usebold">
  <b>
</bl:if>
    Possibly bolded text
<bl:if var="#pro/usebold">
  </b>
</bl:if>
\end{smallverbatim}

\noindent Although the intent is reasonable, XML requires
proper nesting of elements and thus disallows this code.  Instead, \etl{}
supports that behaviour using a special \smtexttt{bl:if-var} attribute
on an arbitrary literal result element:

\begin{smallverbatim}
<b bl:if-var="#pro/wantbold">
  Possibly bolded text
</b>
\end{smallverbatim}

\noindent where the output of \emph{both} the open and close
\smtexttt{b} tags is controlled by the test of the single variable
(and the contents of the \smtexttt{b} element are always
executed). This technique also lets us factor out the guard, thus
eliminating the possibility of a mismatch between the test used for
the start tag and the one used for the end tag.

Comments are another subtle aspect of markup templating
languages. They fall into two categories: 1) traditional comments
intended for the developers never to be part of the generated output;
and 2) target-language markup comments that are intended to be sent
over the wire as part of the response document.  Similar to XSLT, the
former are written as simple XML comments using the \smtexttt{<!--
... -->} syntax, while comments intended for the response are
constructed using the \smtexttt{bl:comment} primitive.

%For example:
%\begin{smallverbatim}
%<!-- This comment is not seen by end user -->
%<bl:comment> 
%This text gets copied into the response 
%document inside of &lt;!-- .. --&gt; delimiters.
%</bl:comment>
%\end{smallverbatim}

Finally, to support internationalization of templates, developers can
choose to use the \smtexttt{bl:tt} (token translation) primitive in
all places where literal text or markup would appear.  For example,
instead of writing \smtexttt{Hi <bl:get var="name"/>}, a properly
internationalized template might read:

\begin{smallverbatim}
<bl:tt id="greet1">Hi</bl:tt><bl:get var="name"/>
\end{smallverbatim}

\noindent Each template has a corresponding dictionary of token-translation
definitions for the various locales that have been defined.  Based on
the request's locale selection (either from a stylized URL or the
\smtexttt{Accepts-Language} header), the appropriate dictionary is
used to replace each \smtexttt{bl:tt} element with the XML fragment to
which the given identifier maps.

\subsection{Controlling whitespace}
\label{ssec-whitespace}

Whitespace characters in a source template have mixed
uses.\footnote{Whitespace that is not a part of the XML
Infoset~\cite{XML-infoset}, such as whitespace between attributes
inside element tags, is discarded by the XML processor before the
application sees it and is therefore not
controlled by the rules described in this section.}  In some cases,
the developer wishes to improve the readability of the program by
using indentation or blank lines.  In other cases, the whitespace is
intended to be copied into the output document or a variable's value.
The \smtexttt{xml:space} attribute provided by the XML
standard~\cite[2.10]{XML} is not sufficiently expressive to support
the diverse needs of the template author. Careful control over which
whitespace is deemed meaningful is critical to generating the right
markup. It also can improve performance and reduce memory and
bandwidth consumption by eliminating unnecessary extra characters from
going over the wire.


\begin{figure}[tb]
\begin{centering}
\includegraphics[height=1.5in]{etl-whitespace-rules.eps}
\caption{XML has various kinds of whitespace nodes.  \etl{} permits
careful control over which nodes are considered significant. \label{fig-ws-rules}}
\end{centering}
\end{figure}

\etl{} permits fine-grained control over the whitespace that will be
generated via two orthogonal special attributes that are allowed on
every XML element in source \etl{} documents: \smtexttt{@bl:space-nodes}
and \smtexttt{@bl:text-nodes}.  These attributes are inherited by
contained (i.e., children) elements and their contents unless
overridden.  They control the various classes of whitespace
illustrated in \figref{ws-rules}: the \smtexttt{@bl:space-nodes}
attribute controls
whitespace-only (and whitespace-only content) nodes (1, 5, 6, and 7 in
the figure), while \smtexttt{@bl:text-nodes} controls
leading/internal/trailing whitespace of text nodes (2, 3, and 4 in the
figure).  Importantly, these whitespace rules are statically-scoped: a
called template is not impacted by a calling template's attribute
annotations.

The allowed settings for \smtexttt{@bl:space-nodes} are: a)
\textbf{\smtexttt{preserve}}, to leave the whitespace unchanged; b)       
\textbf{\smtexttt{compact}}, to replace sequences of 1 or more
      whitespace characters with a single space (0x20); c)      
\textbf{\smtexttt{strip}}, to eliminate the text node entirely; or d)
\textbf{\smtexttt{normalize}} to strip whitespace nodes that contain only
newline (0x0A) characters entirely and replace sequences of 1 or more
whitespace characters that include a space or a tab with a single
space (0x20). For \smtexttt{@bl:text-nodes}, the above settings are
extended by \textbf{\smtexttt{trim}} which trims all leading and
trailing whitespace.

\subsection{Custom tags}
\label{ssec-custom-tags}

\etl{} allows custom tags to define new abstractions only in terms of 
built-in primitives.  The mechanism \etl{} provides is based on abstract
syntax tree (AST) rewriting similar to Scheme's hygienic macros
and other syntactic macro systems~\cite{R5RS,Aitken97}.
Given that the AST of an \etl{} template is simply the XML source code
itself, we simply use XSLT to describe the rewrite rules (see
\figref{processing-stages}).  Those rules are then applied to the
source template thus reducing that code to contain only the core
language.  That reduced template is then byte-compiled for
execution. This approach allows a great deal of flexibility in new
abstractions without compromising our tight control over the limited
behaviour we permit the presentation layer.

%% GREGB:FIXME:: I could give an example here

\begin{figure}[tb]
\begin{centering}
\includegraphics[width=.85\linewidth]{processing-stages-simple.eps}
\caption{The pre-execution processing of various templating languages
can be fairly involved. The pipeline (a) illustrates a mod\_perl-like
system where the template is parsed and then byte-compiled into the
runtime artifact, while (b) shows a JSP-like preprocessing system
where the template is first converted into textual source code which
then is parsed and compiled.  \etl{}'s use of XML (c) allows the web
developer to manipulate and analyze the AST thus simplifying the
system. \label{fig-processing-stages}}
\end{centering}
\end{figure}


\section{Implementation \& experience}
\label{sec-implementation}

A byte-code compiler and runtime for the Extensible Templating
Language is an integral part of InfoSpace's \etl{} Server 2.0.
Byte-compilation happens transparently and results in up to a
100\% performance improvement over the fully interpreted language \etl{}
replaces. The \etl{} Server is architected as an ISAPI extension to
Microsoft's IIS and could be easily ported to any web server that
exposes a similar Extension Control Block interface.  IIS is used to
manage the raw socket connections and many HTTP protocol details, but
\etls{} generates the response for all incoming requests.  The
implementation of \etls{} is about sixty thousand non-comment, non-blank
lines of C++ code.

In addition to supporting the \etl{} language, our secondary design goals
in building \etls{} were: 1) to be an appliance network box, so that all
interactions with the server could occur via simple network protocols
such as HTTP and SMB fileshares; 2) support easy management via HTTP
and platform specific management interfaces such as the Microsoft
Management Console (MMC) and the Service Control Manager; and 3) to
provide support for secure debugging and run-time reflection on 
template execution.

\begin{figure}[tb]
\begin{centering}
\hspace*{-0.05\linewidth}\includegraphics[width=1.1\linewidth]{etls-admin-screenshot.eps}
\caption{The \etl{} Server has a web-based administration interface to
support configuration and management.
\label{fig-etls-admin}}
\end{centering}
\end{figure}

To support administrative management of the server, we implemented
special primitives in a separate \smtexttt{admin} namespace that
expose reflection and configuration capabilities.  For example, with
these primitives you can retrieve an XML dump of the state of the
cached URL-to-template mapping or reset that cache.  These special
capabilities are only available when the request is properly
authenticated and authorized.  To facilitate easy management of the
server, we implemented a web application (in \etl{}, of course) that
organizes and exposes these underlying primitives and integrates the
documentation for the server (see \figref{etls-admin}).  All server
parameters are settable via \smtexttt{admin:*} primitives, and the
server is configured by executing a distinguished
\smtexttt{etl-server-conf.etl} template at startup.

To facilitate debugging, \etls{} supports numerous special URL
parameters, each prefixed with \smtexttt{etl-}, that enable special
processing of the request.  As with the special primitives, these
extra behaviours function only when the request is authenticated and
authorized. For example, \smtexttt{?etl-show-resolution} suppresses
the normal response document and instead generates an XML document
that describes the dynamic call graph used in servicing the request.
Another parameter, \smtexttt{?etl-decompile} can be added to a URL to
request that the server dump the internal byte-compiled representation
as the response (see \figref{etl-decompile}).  Other parameters, such
as \smtexttt{?etl-no-random} and
\smtexttt{?etl-dummy-ads}, simplify testing by eliminating some
major points of non-determinism in template execution.  These
capabilities enormously simplify regression testing.

\begin{figure}[tb]
\begin{smallverbatim}
Template `books.html.etl' has 0 errors.
0 template('books.html.etl') {
1  set_simple(#xml/books := '...')
2  #element('<html>','</html>') {
3   #element('<table>','</table>') {
4    for-each(#xml/books/book) {
5     #element('<tr>','</tr>') {
6      #element('<td>','</td>') {
7       get(@author)
       } // #element('<td>','</td>')
8      #element('<td>','</td>') {
9       get(@title)
       } // #element('<td>','</td>')
      } // #element('<tr>','</tr>')
     } // for-each(#xml/books/book)
    } // #element('<table>','</table>')
   } // #element('<html>','</html>')
  } // template('books.html.etl')
\end{smallverbatim}
\caption{To support debugging, the \etl{} server permits decompilation of
the internal representation of the \etl{} template from
\figref{etl-books}.  The nesting of elements 
is preserved, but the byte-codes have been linearized for performance.
\label{fig-etl-decompile}}
\end{figure}

Although the special \smtexttt{etl-*} parameters are very valuable,
often single-stepping through code or using breakpoints still is the
best way to track down specific problems.  To that end, we built an
ActiveX-based debugger (\figref{debugger-screenshot}) that embeds
itself in Internet Explorer and communicates with the \etl{} server via a
separate persistent TCP connection.  It supports single stepping (both
forwards and backwards) as well as the setting of breakpoints and the
inspection of variables and request parameters.  The debugger also
provides a convenient display mechanism for trace messages (output
using \smtexttt{bl:trace}) and other warning messages that would
normally be sent to the standard-error output.

\begin{figure}[tb]
\begin{centering}
\hspace*{-0.03\linewidth}\includegraphics[width=1.1\linewidth]{debugger-screenshot.eps}
\caption{The \etl{} debugger has five main components: 1) the byte-codes being
executed; 2) the presentation of the response thus far generated; 3)
the address and tool bars; 4) the warning and trace message console; and 5)
the variable inspection pane. \label{fig-debugger-screenshot}}
\end{centering}
\end{figure}

InfoSpace's production web tree contains over sixty thousand \etl{}
templates and the clusters of \etl{} Servers serve millions of
requests per day.  Many of the current templates were generated by a
complex multi-step automatic migration process from a lower level
proprietary templating language that pre-dates \etl{}\@.  The automatic
migration was made possible by the fact that the preceding language,
too, was very restrictive on the language level constructs it
afforded.  However, that language, like ASP and JSP, was text-based,
not markup-based, and used a proprietary and obscure syntax that made
writing tools and analyzing the source code especially troublesome.

As part of migrating from our legacy language to \etl{}, we wrote a
lint-style checker to uncover ambiguities in the original source
templates.  That script uncovered about forty-five thousand total
major warnings spanning about fourteen thousand templates that required
a human to resolve an ambiguity or an error. Fortunately, most of the
corrections were straightforward and the entire process only took a
couple of months of background work by our web development
teams.  The quantity of bugs found in the templates of the legacy
language suggest the substantial additional value that the static checking
of \etl{} provides.

Currently, only a couple hundred templates have been authored directly
in \etl{} outside of the server development team.  Most notably the
administration interface was written using the tools described above,
and the feedback from those web developers has been extraordinarily
positive.

%%% 
\section{Related work}
\label{sec-related-work}

Earlier work, including JavaML, argues that XML adds much value as
a complementary representation for source
code~\cite{Badros-www9,Power2002,Schonger2002,Gondow2002}. \etl{} takes
the next step and uses XML as the primary representation for a markup
templating language---an approach that proves especially worthwhile because
template developers are already writing markup directly.

XSLT~\cite{XSLT} is the only popular templating language that uses a
restricted language.  Unfortunately, it suffers from three fatal
weaknesses for our intended usage scenario: 1) its declarative model confuses
developers used to procedural programming; 2) it is a bit too limited,
often causing the need to use it in conjunction with a server-side
scripting language such as JavaScript or Visual Basic (in particular,
XSLT does not support building its data model by doing web service or
other HTTP requests); and 3) it lacks a streaming output mechanism,
thus limiting its applicability to large incrementally-processable
documents or situations where the desired user experience makes it
important to send some HTML over the wire while the remainder of
processing occurs.  XExpr~\cite{XExpr} and XInclude~\cite{XInclude} are
two other languages that use an XML representation but focus on
domains even more restricted than the markup-generating template
problem that \etl{} solves.

LAML~\cite{Laml,Laml-WWW2002} has similar goals to \etl{}, but takes an
opposite approach: LAML embeds the simpler markup languages 
in Scheme, an especially powerful and expressive language.  Each
markup element has a corresponding mirror procedure that outputs the
appropriate tags, does validity checking, and otherwise reflects the
semantics of the markup language.  Thus, LAML gets many of the same
benefits of \etl{} with respect to increasing the probability of
generating well-formed markup.  However, it uses the syntax of
Scheme's S-expressions rather than XML markup, thus forgoing the
ability to leverage XML-based tools for analysis.  Additionally, the
extra power of Scheme is in direct contradiction of our goal of
reducing the expressiveness of the language.  A similar approach has
been applied by embedding markup in Haskell and Curry, two other
functional languages~\cite{Thiemann2002,Meijer2000,Hanus2001}.

\verb|<bigwig>| is another significant research project~\cite{BigWig} that has
similar goals.  That work adds a first class markup-fragment type to a
conventional programming language.  That system is more aggressive
in its verification of the well-formedness of markup values: an
iterative data-flow analysis bounds the possible values which can then
be confirmed to be valid~\cite{Brabrand2001}. As with the other
approaches that use a general-purpose language, the benefits \etl{}
provides in separating the presentation details from back-end
applications are lost.


%%% 
\section{Conclusions \& future work}
\label{sec-conclusion}

The Extensible Templating Language questions a
fundamental assumption: that the front-end markup-generating engine of
a multi-tier web application requires a general-purpose programming
language.  We designed \etl{} by carefully choosing the minimal required
language constructs, giving those features an XML syntax, and
permitting them to be intermingled directly with literal markup.
Limiting the power of the templating language forces improved
separation of front-end presentation details from back-end application
logic.  Additionally, \etl{} is simpler than other templating languages,
exposing a unified XML data model and integrating cleanly with modern
Internet and web standards.

By leveraging a 100\% XML syntax, we make analyses and tools
especially easy.  In particular, we show how the structure of
the source program can be used to reduce the probability of generating
ill-formed or invalid response documents. We introduced a novel use of
pairs of attributes, called slots, to improve the type-safety of the
XML syntax.  \etl{} also contributes a taxonomy of XML whitespace along
with rules for finer-grained control of which whitespace is
significant.  To support extensible abstractions, \etl{} uses XSLT as a
rewrite engine for macro-like custom-tags. We have over a year of
experience running \etls{} in production and it serves millions
of requests per day.

While developing \etl{}, our novel uses of XML exposed a couple of
limitations in important web standards.  First, \etl{}'s slot syntax
would be more precisely validated by the XML Schema Definition
language if XSD supported better control over sets of attributes.
There is currently no way to express the notion that exactly one of a
pair of attributes must be given, thus our system must check this
constraint procedurally.  Second, we have found limitations
in using XSLT for source to source transformations of \etl{} templates.
A template developer may care about non-infoset syntactic artifacts
such as newlines between attributes, but XSLT discards those
details~\cite{VanDeVanter2001}.

Thus far, we have been satisfied with increasing our ability to catch
markup errors statically.  Enabling provably well-formed response
documents is a noble goal and time will tell whether our needs will
justify applying \verb|<bigwig>|'s lessons.  Another interesting area
for future work is using Perl-like taint checking on input variables
to improve the security of the server. Combined with server-integrated
support for input parameter integrity and checking, these features could defeat many
attacks~\cite{ScottSharp02}.

Over the coming months, we expect to learn a great deal from the
increased usage of the Extensible Templating Language and its server,
but already \etl{} and \etls{} have been an enormous success in revitalizing
the InfoSpace platform.

\section{Acknowledgments}
\label{sec-ack}
This research is supported by InfoSpace and its advanced server
development group.  I thank Russ Arun and Steve Newman for their early
recognition of the value of this approach and support.  \etl{} itself was
designed in collaboration with Abhishek Parmar and is influenced by
the legacy language of its predecessor which was implemented by
Jean-Remy Facq.  The \etl{} Server was built by the author along with
Abhishek Parmar, Venkatesh Juryala, Sridhar Koneru, Mark Sandori,
Michael Harrison, Kris Bradley, Angela Plyler, Sunil Thomas, and
Howard Zhao.  Testing of \etls{} was ably performed by Zine Rif, Sriram
Krishnan, Michael Schaffer, Shavkat Azimov, Jeff Wells, Ilian
Georgeiw, and Russell Ashmun, and credit goes to Antonio Casacuberta
for continued support of the server group.  I also thank Jeff
Torgerson, Matthew Benedict, Vasanth Cattamanchi and all of the
InfoSpace web developers for their contributions. \etls{} is a trademark
of InfoSpace, Inc.


\bibliographystyle{abbrv}
\bibliography{etl-www2003}
\balancecolumns

%\appendix
%Appendix A
%\section{}
%\balancecolumns % GM July 2000

\end{document}
