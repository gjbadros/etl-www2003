%%% $Id$
%%% Copyright (C) 2002 Greg J. Badros <greg.badros@infospace.com>
%%
%
% This file should be compiled with V1.0 of "www2003-submission.cls"
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V1.0) produces:
%       1) NO Permission Statement
%       2) WWW'03-specific conference (location) information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%

\documentclass{www2003-submission}
\usepackage{times}
\usepackage{moreverb}
\usepackage{floatflt}
\usepackage{url}

\newcommand{\B}{\discretionary{}{}{}}
\newcommand{\smtt}{\small}
\newcommand{\smtexttt}[1]{{\small\texttt{#1}}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\tableref}[1]{Table~\ref{#1}}
\newcommand{\tm}{{\scriptsize $^{\mbox{tm}}$}}

\begin{document}
%
\title{The Extensible Templating Language: \\
       Improving Static Analysis of Markup Generation}

\numberofauthors{1}

\author{
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
%% e-mail address with \email.
\alignauthor Greg J. Badros\\
       \affaddr{InfoSpace, Inc.}\\
       \affaddr{601 108th Ave. NE, Suite 1200}\\
       \affaddr{Bellevue, WA ~ USA}\\
       \email{greg.badros@infospace.com}
}
\date{2 November 2002}
\maketitle
\begin{abstract}
ETL....
\end{abstract}

% A category with only the three required fields
%% GREGB:FIXME::
\category{D.2}{Software}{Software Engineering}
\category{D.3}{Software}{Programming Languages}

% GREGB:FIXME:: any terms?
%\terms{}

\keywords{Static analysis, web server, templates, XML, XSLT, markup, WML, HTML.}

\section{Introduction}

Server-side dynamically-generated web pages have become increasingly
common and more complex.  The loosely-coupled client/\B{}server model
implied by the current breed of applications deployed via the World
Wide Web presents substantial new complexities for application
developers, and a variety of new programming languages and paradigms
attempt to address these novel problems.  One important characteristic
of this new world of software development is the need to generate HTML
or other markup languages to describe the client-side presentation and
behaviour.

The original server-side dynamic markup-generation capabilities of the
Web were defined by CGIs.\cite{CGI} For each request, the web server
maps HTTP request details into environment variables, command-line
arguments, and the standard file descriptors.  In particular, the
standard output written by that process was sent by the Web server as
the response to the client browser (instead of simply responding with
an unchanging file from disk).  Over time, various techniques arose to
reduce the cost of each request: extension mechanisms such as the
Apache module system~\cite{ApacheModules} and scripting languages
hosted by the Web server have increased performance by eliminating
process creation overhead.

The variety of server-side scripting is dominated by expressive and
flexible general-purpose programming languages such as
Java~\cite{Java}, Perl~\cite{Perl}, and PHP~\cite{PHP}.  Ironically,
the languages are then used in fairly restricted ways, often being
tied to a templating language (e.g., JSP~\cite{JSP} for Java or
HTML::Template~\cite{HTML-Template} for Perl).  For example, consider
the PHP template in \figref{php-books}.  The only constructs required
by the template are a) some means of populating a data model from the
back-end business logic (line 1); b) data-driven iteration (line
5-6); and c) simple expression evaluation to access parts of the data
model (lines 7 and 9). % GREGB:FIXME:: check these line numbers

\begin{figure}[htbp]
\begin{listing}{1}
<? $books = GetBooks(...); ?>
<html>
 <table>
  <tr>
   <? for ($i = 0; 
           $i < count($books); ++$i) { ?>
     <td><? print($books[$i][author]); ?>
         </td>
     <td><? print($books[$i][title]); ?>
         </td>
   <? } ?>
  </tr>
 </table>
</html>
\end{listing}%$
\caption{PHP template illustrating the simplicity of the programming
language constructs required by typical templates.
\label{fig-php-template}}
\end{figure}

Unfortunately, for most contemporary web application development
frameworks, the restrictions desired of the front-end templating layer
are imposed only by process and convention.  Template authors are
asked to limit themselves to a subset of the available features of a
language as a means of facilitating scalable, secure, well-behaved
systems.  Importantly, however, there is nothing inherent that
prevents template executions from, for example, making individual
database connections (which would impact performance) or maintaining
undesirable server-side state (which would impose additional
requirements on the load-balancing mechanism and reduce scalability).
These concerns are intensified because many development organizations
encourage a strong separation between the web developers and back-end
application developers. While web developers have substantial
expertise in HTML, user-interface design, and client-side scripting,
their responsibilities often do not include consideration of the
larger architecture.

Another substantial problem with existing templating technologies is
that they often involve the lexical mixing of two separate programming
paradigms.  JSP, for example, is implemented in terms of a
pre-processing rewrite of the template into a Java servlet.~\cite{JaveServlet}
Pre-processing approaches are convenient for programmer expressiveness
but have a huge hidden cost in complicating software engineering
analyses and tools that would otherwise help understand, maintain, and
evolve the complex systems~\cite{PCP3,EvilMacros,StroustropDnEChapterAboutCpp}.
The precise analysis of an arbitrary JSP template necessarily requires
full knowledge of both the rewrite rules and the semantics of Java.

%% GIVE EXAMPLES OF VALUABLE ANALYSES!!!
\subsection{Analysis of markup templates}

The various templating languages all have one primary goal: to
generate markup to be returned to the requesting user agent.  It is
important that the markup created conforms to appropriate Internet
standards.  For example, WML markup needs to first be well-formed XML
and second be valid with respect to the appropriate
schemata~\cite{WML}.  Although HTML browsers are more forgiving of
improper syntax, best-practices still dictate that the markup returned
be in compliance with the HTML specification~\cite{HTML}.  

Tools such as HTMLTidy~\cite{HTMLTidy} are available to check the
responses from servers for conformance, but often testing involves
simply using various browsers to exercise the application while
looking for bugs.  Both of these approaches require exhaustively
visiting every page of interest--often a very large search space.
Ideally, we would prefer a way to analyze the source templates
themselves to gain confidence that they will, in fact, generate proper
markup.  If static analysis of templates can rule out the possibility
of certain kinds of errors, testing time and costs can be dramatically
reduced.

Another important requirement is to support ad-hoc queries of
the source code templates. For small and simple dynamic web applications,
the automated analysis of templates is often unnecessary: a web
developer or two understands all of the code.  Over time, however,
these simple applications easily grow in size and complexity such that
tools analyzing the templates become an essential part of maintaining
and evolving the system. For example, a site may wish to add an extra
input field to all of its registration forms.  If a generic form is
not already factored out into a common location, the first step in
approaching the task is finding all of the registration forms.  Or
suppose a new handheld device has a bug in handling an HTTP response
header: we need to identify all the code in the system that may
generate that header.

Typically, web developers approach to above scenarios with an arsenal
of imprecise lexical tools such as \smtexttt{find} and
\smtexttt{grep}.  While searching for a substring or regular
expression may satisfy some simple queries, when the desired query has
additional structure, lexical approaches fall short.  No regular
expression will let us identify all unreachable templates (i.e., we
want to find dead code) so that we can simplify the application by
eliminating those templates.  To analyze more deeply, we need to
uncover the structure of the templating language.  Typically, that
requires a language-specific parsing approach for which fewer tools
exist.

\subsection{XML supports analyses}

An increasingly popular approach to performing structured queries of
programming language source code is to use standard XML tools such as
XSLT~\cite{XSLT} and XQuery~\cite{XQuery} to operate over a
complementary XML-based representation~\cite{JavaML,others}.  With a
carefully-chosen XML representation, valuable semantics of the code
are immediately available to XPath expressions, thus facilitating a
broad class of source code tools.  However, for a general-purpose
programming language, XML is unwieldy for use as the primary
representation: the conventional grammer-based language is edited by
humans and is only converted into XML for the tools to leverage.

This research applies the benefits of an XML representation of source
code to domain-specific markup templating languages.  Importantly,
web developers working with templating languages are already writing
markup directly, thus making it natural for them to express the logic
of their dynamic templates directly in markup as well.  This
observation eliminates the dual representation problem that limits the
value of XML when applied to general purpose programming language.

In this paper, I introduce the Extensible Templating Language.  From
one perspective, ETL is a 100\% XML-based templating language that
embeds programming language constructs directly in the XML
representation, intermingled with literal target-language markup.
Alternatively, we can view ETL as an imperative domain-specific
programming language that uses XML as its surface syntax and
simplifies the writing of programs that generate markup languages.

ETL leverages the well-formedness and local-validity checks of the
source template to support the correctness of the generated response
markup.  Additionally, because of its use of XML as a representation,
it simplifies ad-hoc software engineering analyses to better support
evolution and maintenance of large dynamic web applications.  We have
built an ETL runtime inside of a production-quality web server, the
Extensible Templating Language Server.  ETLS is currently employed by
InfoSpace to serve over forty million requests per day using over
sixty thousand ETL templates.

\subsection{Outline of paper}

Section \ref{sec-} ....

%%% 
\section{Background}

%% JSP/XML
%% XSLT

\subsection{Current templating strategies}

\subsection{Comparison of approaches}

%\begin{table}
%\centering
%\caption{Summary of existing templating approaches.}
%\begin{tabular}{|c|c|l|} \hline
%\\ \hline
%\hline\end{tabular}
%\end{table}


%%% 
\section{ETL: A better approach}


%%% 
\section{Benefits of ETL}

%%% 
\section{Implementation \& experience}

%%% 
\section{Related work}

%% LAML
%% BigWig


%%% 
\section{Conclusions \& future work}


%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}

\bibliographystyle{abbrv}
\bibliography{etl-www2003}  % sigproc.bib is the name of the Bibliography in this case

%
%\balancecolumns
\appendix
%Appendix A
%\section{}
%\balancecolumns % GM July 2000

\end{document}
